from config import ROOT, MEGAD_NAME, DEVICE, THRESHOLD
from src.transforms import transforms_aliked, transform_tta_mega
from src.dataset import load_datasets
from src.fusion_exp import build_experimental_fusion  # experimental fusion
from src.matcher import build_megadescriptor, build_aliked, build_eva02, build_dinov3
from src.fusion_head import FusionMLP
from src.utils import set_seed

import timm
import numpy as np
import pandas as pd

from src.metrics import calculate_statistical_metrics, calculate_core_metrics  # ì§€í‘œ ê³„ì‚° í•¨ìˆ˜
import os

def main():
    set_seed(42)

    # exp 1. ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ: 'isotonic' ë˜ëŠ” 'logistic'
    CURRENT_CALIB_TYPE = 'isotonic' 
    # exp 2. ëª¨ë¸ë³„ ê°€ì¤‘ì¹˜ ì„¤ì •: [ALIKED, MegaDescriptor, EVA02]
    CURRENT_WEIGHTS = [0.34, 0.33, 0.33]
    THRESHOLD = 0.35  # config.pyì˜ THRESHOLDêº¼ ê°€ì ¸ì˜´

    # 1. Load the full dataset
    dataset, dataset_db, dataset_query, dataset_calib = load_datasets(ROOT, calibration_size=1000)

    # 2. Load MegaDescriptor model
    model_mega = timm.create_model(MEGAD_NAME, num_classes=0, pretrained=True).to(DEVICE)

    # 3. ê° ëª¨ë¸ ë³„ Matcher(pipeline) build
    matcher_mega = build_megadescriptor(model=model_mega, transform=transform_tta_mega, device=DEVICE)
    matcher_aliked = build_aliked(transform=transforms_aliked, device=DEVICE)
    matcher_eva = build_eva02(device=DEVICE)  # ìˆ˜ì •1: EVA02 matcher ì¶”ê°€

    # 4. Fusion ëª¨ë¸ ë¹Œë“œ (ALIKED + Mega + EVA02)
    fusion = build_experimental_fusion(
        dataset_calib, dataset_calib,
        matcher_aliked, matcher_mega, matcher_eva,   # ìˆ˜ì •1
        priority_pipeline=matcher_mega,              # í›„ë³´ ì„ ì •ìš© ë©”ì¸ íŒŒì´í”„ë¼ì¸
        weights=CURRENT_WEIGHTS,
        calib_type=CURRENT_CALIB_TYPE
    )

    # 5. Compute predictions per query group
    predictions_all = []
    image_ids_all = []
    scores_all = []  # ìˆ˜ì •2: ì ìˆ˜ ì €ì¥ìš©

    for dataset_name in dataset_query.metadata["dataset"].unique():
        query_subset = dataset_query.get_subset(dataset_query.metadata["dataset"] == dataset_name)

        # 6. WildFusion í•œ ë²ˆì˜ í˜¸ì¶œë¡œ 3ê°œ ëª¨ë¸ì´ í†µí•©ëœ ì ìˆ˜ ì‚°ì¶œ
        # ìˆ˜ì •3: ë‚´ë¶€ì ìœ¼ë¡œ ALIKED, Mega, EVA02ê°€ ê°ê° ê³„ì‚°ë˜ê³  ê°€ì¤‘ì¹˜ í•©ì‚°ë¨
        combined_sim = fusion(query_subset, dataset_db, B=25)

        # ê²°ê³¼ ë„ì¶œ (Top-1 + threshold): idx / score ê³„ì‚°
        idx_sorted = combined_sim.argsort(axis=1)
        top_idx = idx_sorted[:, -1]
        p_top1 = combined_sim[np.arange(len(query_subset)), top_idx]  # Top-1 ì ìˆ˜

        labels = dataset_db.labels_string
        predictions = labels[top_idx].copy()
        predictions[(p_top1 < THRESHOLD)] = "new_individual"  # threshold ë¯¸ë‹¬ ì‹œ new_individual

        predictions_all.extend(predictions)
        image_ids_all.extend(query_subset.metadata["image_id"])
        scores_all.extend(p_top1)   # ìˆ˜ì •2: top-1 ì ìˆ˜ ì €ì¥
    
    # 6. í†µê³„ ì§€í‘œ ê³„ì‚° ë° ì¶œë ¥ (ìˆ˜ì •2)
    # í˜„ì¬ ì •ë‹µ(ground_truth)ì´ ì—†ìœ¼ë¯€ë¡œ core_metricsëŠ” 0ìœ¼ë¡œ ë°˜í™˜ë¨
    raw_conf, unc, n_ratio, rel_score = calculate_statistical_metrics(predictions_all, scores_all)
    rank1, m_ap, f1 = calculate_core_metrics(predictions_all, scores_all, ground_truth=None)

    # ê°€ì¤‘ì¹˜ ì •ìˆ˜í™”
    w_int = [int(round(w * 100)) for w in CURRENT_WEIGHTS]

    # ì‹¤í—˜ ì§€í‘œ ì €ì¥ìš© ë°ì´í„° ìƒì„±
    metrics_data = {
        "calibration": CURRENT_CALIB_TYPE,
        "aliked_w": w_int[0],
        "mega_w": w_int[1],
        "eva_w": w_int[2],
        "mean_confidence": round(raw_conf, 4),
        "uncertainty": round(unc, 4),
        "new_ratio": round(n_ratio, 4),
        "reliability_score": round(rel_score, 4),
        "rank1": rank1,
        "mAP": m_ap,
        "f1_score": f1
    }

    # metrics_history.csvì— ëˆ„ì  ì €ì¥ (ì—†ìœ¼ë©´ ìƒì„±, ìˆìœ¼ë©´ ì¶”ê°€)
    metrics_df = pd.DataFrame([metrics_data])
    metrics_log_file = "metrics_history.csv"
    
    if not os.path.exists(metrics_log_file):
        metrics_df.to_csv(metrics_log_file, index=False)
    else:
        metrics_df.to_csv(metrics_log_file, mode='a', header=False, index=False)
    
    print(f"ğŸ“Š Metrics log updated in {metrics_log_file}")

    # 7. Save to CSV
    df = pd.DataFrame({"image_id": image_ids_all, "identity": predictions_all})
    output_name = f"{CURRENT_CALIB_TYPE}_Aw{w_int[0]}_Mw{w_int[1]}_Ew{w_int[2]}.csv"   # íŒŒì¼ëª…ì— ì‹¤í—˜ ë³€ìˆ˜ í¬í•¨
    df.to_csv(output_name, index=False)
    print(f"âœ… {output_name} saved!")

if __name__ == '__main__':
    from multiprocessing import freeze_support
    freeze_support()
    main()